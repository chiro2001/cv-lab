{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于python基础库，搭建卷积神经网络，并用该网络进行手写字符识别\n",
    "\n",
    "#### 本程序主要基于python的numpy、math等基础函数库，完成了CNN训练的前向传播、后向传播、随机梯度下降更新等主要的函数功能；\n",
    "\n",
    "#### 并基于该程序，在MNIST数据集上进行手写字符识别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import,division,print_function\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "from six.moves import xrange\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#包推荐版本见requirements"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一些超参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE=28           #图片大小\n",
    "NUM_CHANNELS=1          #输入图片通道数\n",
    "PIXEL_DEPTH=255         #灰度\n",
    "BATCH_SIZE=64           #训练时的batch size\n",
    "NUM_LABELS=10           #类别数量\n",
    "MAX_EPOCHS = 1          #训练epochs\n",
    "SEED=2330               #random seed\n",
    "EVAL_FREQUENCY = 100    #验证频率\n",
    "EVAL_BATCH_SIZE = 64    #验证时的batch size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入MNIST训练数据集，并将训练集划分出验证集\n",
    "\n",
    "具体函数请参看`data_helper.py`文件，已实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data,  ./data/train-images-idx3-ubyte.gz\n",
      "Extracting labels, ./data/train-labels-idx1-ubyte.gz\n",
      "Extracting data,  ./data/t10k-images-idx3-ubyte.gz\n",
      "Extracting labels, ./data/t10k-labels-idx1-ubyte.gz\n",
      "train data size:  55000\n",
      "train data shape:  (55000, 28, 28, 1)\n",
      "train label shape:  (55000, 10)\n",
      "test data shape:  (10000, 28, 28, 1)\n",
      "test label shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "from data_helper import load_train,load_test\n",
    "\n",
    "def onehot(targets, num):\n",
    "    result = np.zeros((num, 10))\n",
    "    for i in range(num):\n",
    "        result[i][targets[i]] = 1\n",
    "    return result\n",
    "\n",
    "validation_size = 5000\n",
    "train_data,train_labels,validation_data,validation_labels = load_train(validation_size,IMAGE_SIZE, NUM_CHANNELS, PIXEL_DEPTH)\n",
    "test_data,test_labels = load_test(IMAGE_SIZE, NUM_CHANNELS, PIXEL_DEPTH)\n",
    "\n",
    "train_labels = onehot(train_labels, 55000)\n",
    "validation_labels = onehot(validation_labels, validation_size)\n",
    "train_size = train_labels.shape[0]\n",
    "print(\"train data size: \",len(train_data))\n",
    "print(\"train data shape: \",train_data.shape)\n",
    "print(\"train label shape: \",train_labels.shape)\n",
    "print(\"test data shape: \", test_data.shape)\n",
    "print(\"test label shape: \", test_labels.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图片示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y is: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 1\n",
    "plt.imshow(train_data[index].reshape((28,28)),cmap = plt.cm.gray)\n",
    "print(\"y is: \"+str(train_labels[index]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 卷积操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img.shape: \t (2, 28, 28, 1)\n",
      "conv_out.shape:  (2, 26, 26, 2)\n",
      "conv_back.shape: (2, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, layer_shape, k_size=5, k_num=32, strides=1, seed=2330):\n",
    "        #输入的维度 （batch，height，width，channels）\n",
    "        self.input_shape = layer_shape\n",
    "        self.input_batch = layer_shape[0]\n",
    "        self.input_height = layer_shape[1]\n",
    "        self.input_width = layer_shape[2]\n",
    "        self.input_channels = layer_shape[3]\n",
    "        \n",
    "        self.seed = seed\n",
    "        self.k_size = k_size      #kernel大小\n",
    "        self.strides = strides    #kernel步长\n",
    "        np.random.seed(self.seed)\n",
    "        \n",
    "        #stride和图片大小是否对应\n",
    "        if (self.input_height-self.k_size) % self.strides != 0:\n",
    "            print(\"input tensor height can\\'t fit strides!\")\n",
    "        if (self.input_width-self.k_size) % self.strides != 0:\n",
    "            print(\"input tensor width can\\'t fit strides!\")\n",
    "\n",
    "        #输出的维度\n",
    "        self.output_batch = self.input_batch\n",
    "        self.output_height = (self.input_height-self.k_size) // self.strides + 1\n",
    "        self.output_width = (self.input_width-self.k_size) // self.strides + 1\n",
    "        self.output_channels = k_num\n",
    "        self.delta = np.zeros((self.output_batch, self.output_height, self.output_width, self.output_channels))\n",
    "        \n",
    "        self.output_shape = self.delta.shape\n",
    "        \n",
    "        weights_scale = math.sqrt(k_size*k_size*self.output_channels/2)\n",
    "        #卷积权重初始化\n",
    "        self.weights = np.random.standard_normal((k_size, k_size, self.input_channels, self.output_channels)) / weights_scale\n",
    "        self.bias = np.random.standard_normal(self.output_channels) / weights_scale\n",
    "        #梯度初始化\n",
    "        self.w_gradient = np.zeros(self.weights.shape)\n",
    "        self.b_gradient = np.zeros(self.bias.shape)\n",
    "        \n",
    "        self.col_image = []\n",
    "    \n",
    "    def img2col(self, image, ksize, stride):\n",
    "        # image([batchsize, width ,height, channel])\n",
    "        #取出所有要和kernel做卷积的图像区域\n",
    "        image_col = []\n",
    "        for i in range(0, image.shape[1] - ksize + 1, stride):\n",
    "            for j in range(0, image.shape[2] - ksize + 1, stride):\n",
    "                col = image[:, i:i + ksize, j:j + ksize, :].reshape([-1])\n",
    "                image_col.append(col)\n",
    "        image_col = np.array(image_col)\n",
    "\n",
    "        return image_col\n",
    "        \n",
    "    #计算卷积的前向传播和部分反向求导的参数更新（20 points）\n",
    "    def forward(self, X):\n",
    "        ### start your code\n",
    "        # print(\"kernel size\", self.k_size)\n",
    "        # print(\"self.weights.shape\", self.weights.shape)\n",
    "        # print(\"self.bias.shape\", self.bias.shape)\n",
    "        # print(\"X.shape\", X.shape)\n",
    "        # tips: 对一个batch，逐图片找其要计算的所有区域，计算卷积\n",
    "        self.col_image = []\n",
    "        conv_out = np.zeros(self.delta.shape)\n",
    "        for batch in range(self.input_batch):\n",
    "            # im = X[batch].reshape([1, *list(X.shape)[1:]])\n",
    "            im = X[batch][np.newaxis, :]\n",
    "            conv_col = self.img2col(im, self.k_size, self.strides)\n",
    "            self.col_image.append(conv_col)\n",
    "            # print(\"conv_col.shape\", conv_col.shape)\n",
    "            conv_result_col = []\n",
    "            for i in range(conv_col.shape[0]):\n",
    "                conv_col_reshaped = conv_col[i].reshape((self.k_size, self.k_size, self.input_channels, 1))\n",
    "                m = []\n",
    "                for j in range(self.output_channels):\n",
    "                    mm = np.dot(conv_col_reshaped.reshape([-1]), self.weights[:, :, :, j].reshape([-1])) + self.bias[j]\n",
    "                    m.append(mm)\n",
    "                m = np.array(m)\n",
    "                conv_result_col.append(m)\n",
    "            conv_result_col = np.array(conv_result_col)\n",
    "            # print(\"conv_result_col.shape\", conv_result_col.shape)\n",
    "            conv_out[batch, :, :, :] = conv_result_col.reshape([self.output_height, self.output_width, self.output_channels])\n",
    "            # conv_out[batch] = np.reshape(np.dot(conv_col, self.weights.reshape([-1, self.output_channels])) + self.bias, self.delta[0].shape)\n",
    "        ###end your code\n",
    "        return conv_out        \n",
    "    \n",
    "    def backward(self, delta, lr=0.0001, weight_decay=0.0004):\n",
    "        self.delta = delta\n",
    "        col_delta = np.reshape(delta, [self.input_batch, -1, self.output_channels])\n",
    "        \n",
    "        for i in range(self.input_batch):\n",
    "            self.w_gradient += np.dot(self.col_image[i].T, col_delta[i]).reshape(self.weights.shape)\n",
    "        self.b_gradient += np.sum(col_delta, axis=(0,1))\n",
    "        \n",
    "\n",
    "        pad_delta = np.pad(self.delta, \n",
    "                            ((0, 0), (self.k_size - 1, self.k_size - 1), (self.k_size - 1, self.k_size - 1), (0, 0)),\n",
    "                            'constant', constant_values=0)\n",
    "\n",
    "        flip_weights = np.flipud(np.fliplr(self.weights))\n",
    "        flip_weights = flip_weights.swapaxes(2, 3)\n",
    "        col_flip_weights = flip_weights.reshape([-1, self.input_channels])\n",
    "        col_pad_delta = np.array([self.img2col(pad_delta[i][np.newaxis, :], self.k_size, self.strides) for i in range(self.input_batch)])\n",
    "        delta_back = np.dot(col_pad_delta, col_flip_weights)\n",
    "        delta_back = np.reshape(delta_back, self.input_shape)\n",
    "        \n",
    "        #参数更新\n",
    "        # update weights，bias，清空w_gradient, b_gradient\n",
    "        ### start your code\n",
    "        # tips: weight decay使用：(1-weight_decay)*(weight或者bias)-lr*(w_gradient或者b_gradient),作为一个权重使用\n",
    "        self.weights = (1-weight_decay)*self.weights - lr*self.w_gradient\n",
    "        # self.bias = (1-weight_decay)*self.bias - lr*self.b_gradient\n",
    "        self.bias = (1-weight_decay)*self.bias - lr*self.bias\n",
    "        self.w_gradient = np.zeros_like(self.weights)\n",
    "        self.b_gradient = np.zeros_like(self.bias)\n",
    "        ###end your code\n",
    "        return delta_back\n",
    "\n",
    "def test_():\n",
    "    index = 1\n",
    "    img = train_data[index:index+2, ...]\n",
    "    y = train_labels[index:index+2,...]\n",
    "    print(\"img.shape: \\t\", img.shape)\n",
    "    \n",
    "    conv = Convolution(img.shape, k_size=3, k_num=2, strides=1, seed=2330)\n",
    "    conv_out = conv.forward(img)\n",
    "    print(\"conv_out.shape: \", conv_out.shape)\n",
    "\n",
    "    \n",
    "    conv_back = conv.backward(conv_out, lr=0.0001)\n",
    "    print(\"conv_back.shape:\", conv_back.shape)\n",
    "    \n",
    "test_()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "expect outputs:\n",
    "    \n",
    "    img.shape:       (2, 28, 28, 1)\n",
    "    conv_out.shape:  (2, 26, 26, 2)\n",
    "    conv_back.shape: (2, 28, 28, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. ReLu 层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img.shape: \t (2, 28, 28, 1)\n",
      "conv_out.shape:  (2, 26, 26, 2)\n",
      "relu_out.shape:  (2, 26, 26, 2)\n",
      "relu_back.shape: (2, 26, 26, 2)\n",
      "conv_back.shape: (2, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# rule Activator\n",
    "class Relu:  \n",
    "    def __init__(self, input_shape):\n",
    "        self.delta = np.zeros(input_shape)\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = self.input_shape\n",
    "    \n",
    "    #根据relu函数的形式，写出其前向传播与反向求导的值 （10 points）\n",
    "    def forward(self, x):\n",
    "        ###start your code\n",
    "        self.x = x\n",
    "        # result = x * (x > 0).astype(float)\n",
    "        result = np.maximum(x, 0)\n",
    "        ###end your code\n",
    "        return result\n",
    "    \n",
    "    def backward(self, delta):\n",
    "        ###start your code\n",
    "        # delta = delta * (self.x >= 0).astype(float)\n",
    "        delta[self.x < 0] = 0\n",
    "        ###end your code\n",
    "        return delta\n",
    "    \n",
    "def test_():\n",
    "    index = 1\n",
    "    img = train_data[index:index+2, ...]\n",
    "    y = train_labels[index:index+2,...]\n",
    "    print(\"img.shape: \\t\", img.shape)\n",
    "    \n",
    "    conv = Convolution(img.shape, k_size=3, k_num=2, strides=1, seed=2330)\n",
    "    conv_out = conv.forward(img)\n",
    "    print(\"conv_out.shape: \", conv_out.shape)\n",
    "\n",
    "    relu=Relu(conv_out.shape)\n",
    "    relu_out = relu.forward(conv_out)\n",
    "    print(\"relu_out.shape: \", relu_out.shape)\n",
    "    \n",
    "    relu_back = relu.backward(relu_out)\n",
    "    print(\"relu_back.shape:\", relu_back.shape)\n",
    "    \n",
    "    conv_back = conv.backward(relu_back, lr=0.0001)\n",
    "    print(\"conv_back.shape:\", conv_back.shape)\n",
    "    \n",
    "test_()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "expect output:\n",
    "    \n",
    "    img.shape: \t  (2, 28, 28, 1)\n",
    "    conv_out.shape:  (2, 26, 26, 2)\n",
    "    relu_out.shape:  (2, 26, 26, 2)\n",
    "    relu_back.shape: (2, 26, 26, 2)\n",
    "    conv_back.shape: (2, 28, 28, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. max_pooling 层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img.shape: \t (2, 28, 28, 1)\n",
      "conv_out.shape:  (2, 26, 26, 2)\n",
      "relu_out.shape:  (2, 26, 26, 2)\n",
      "pool_out.shape:  (2, 13, 13, 2)\n",
      "pool_back.shape: (2, 26, 26, 2)\n",
      "relu_back.shape: (2, 26, 26, 2)\n",
      "conv_back.shape: (2, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "class max_pool:\n",
    "    def __init__(self, input_shape, k_size=2, strides=2):\n",
    "        self.input_shape = input_shape\n",
    "        self.k_size = k_size\n",
    "        self.strides = strides\n",
    "        self.output_shape = [input_shape[0], input_shape[1] // self.strides, input_shape[2] // self.strides, input_shape[3]]\n",
    "        self.feature_mask = None\n",
    "    \n",
    "    #计算最大池化的前向传播和反向求导(20 points)\n",
    "    def forward(self, x):\n",
    "        ### start your code\n",
    "        # tips：记录最大池化时最大值的位置信息设为类的变量self.feature_mask，用于反向传播\n",
    "        #       活用np.argmax, 切片等操作\n",
    "        # print(\"x.shape\", x.shape, \"mean\", np.mean(x))\n",
    "        feature = np.zeros((x.shape[0], x.shape[1]//self.strides, x.shape[2]//self.strides, x.shape[3]))\n",
    "        self.feature_mask = np.zeros_like(x)\n",
    "        for batch in range(x.shape[0]):\n",
    "            for channel in range(x.shape[3]):\n",
    "                im = x[batch, :, :, channel]\n",
    "                # print(\"im.shape\", im.shape)\n",
    "                for i in range(0, im.shape[0], self.strides):\n",
    "                    for j in range(0, im.shape[1], self.strides):\n",
    "                        argmax = np.argmax(im[i:i+self.k_size, j:j+self.k_size])\n",
    "                        # print(\"argmax.shape\", argmax.shape, \"argmax\", argmax)\n",
    "                        feature[batch, i//self.strides, j//self.strides, channel] = np.max(\n",
    "                            im[i:i+self.k_size, j:j+self.k_size])\n",
    "                        # print(\"feature.shape\", feature.shape, \"feature\", feature)\n",
    "                        self.feature_mask[batch, i+argmax//self.strides, j+argmax%self.strides, channel] = 1\n",
    "        ### end your code\n",
    "        return feature\n",
    "\n",
    "    def backward(self, delta):\n",
    "        ### start your code\n",
    "        delta = np.repeat(np.repeat(delta, self.strides, axis=1), self.strides, axis=2) * self.feature_mask\n",
    "        ### end your code\n",
    "        return delta\n",
    "    \n",
    "def test_():\n",
    "    index = 1\n",
    "    img = train_data[index:index+2, ...]\n",
    "    y = train_labels[index:index+2,...]\n",
    "    print(\"img.shape: \\t\", img.shape)\n",
    "    \n",
    "    conv = Convolution(img.shape, k_size=3, k_num=2, strides=1, seed=2330)\n",
    "    conv_out = conv.forward(img)\n",
    "    print(\"conv_out.shape: \", conv_out.shape)\n",
    "\n",
    "    relu=Relu(conv_out.shape)\n",
    "    relu_out = relu.forward(conv_out)\n",
    "    print(\"relu_out.shape: \", relu_out.shape)\n",
    "    \n",
    "    pool = max_pool(relu_out.shape,2,2)\n",
    "    pool_out = pool.forward(relu_out)\n",
    "    print(\"pool_out.shape: \", pool_out.shape)\n",
    "    \n",
    "    pool_back = pool.backward(pool_out)\n",
    "    print(\"pool_back.shape:\", pool_back.shape)\n",
    "    \n",
    "    relu_back = relu.backward(pool_back)\n",
    "    print(\"relu_back.shape:\", relu_back.shape)\n",
    "    \n",
    "    conv_back = conv.backward(relu_back, lr=0.0001)\n",
    "    print(\"conv_back.shape:\", conv_back.shape)\n",
    "    \n",
    "test_()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "expect output:\n",
    "    \n",
    "    img.shape: \t  (2, 28, 28, 1)\n",
    "    conv_out.shape:  (2, 26, 26, 2)\n",
    "    relu_out.shape:  (2, 26, 26, 2)\n",
    "    pool_out.shape:  (2, 13, 13, 2)\n",
    "    pool_back.shape: (2, 26, 26, 2)\n",
    "    relu_back.shape: (2, 26, 26, 2)\n",
    "    conv_back.shape: (2, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img.shape: \t (2, 28, 28, 1)\n",
      "conv_out.shape:  (2, 26, 26, 2)\n",
      "relu_out.shape:  (2, 26, 26, 2)\n",
      "pool_out.shape:  (2, 13, 13, 2)\n",
      "flat_out.shape:  (2, 338)\n",
      "flat_back.shape: (2, 13, 13, 2)\n",
      "pool_back.shape: (2, 26, 26, 2)\n",
      "relu_back.shape: (2, 26, 26, 2)\n",
      "conv_back.shape: (2, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "class flatten:\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = [self.input_shape[0], self.input_shape[1] * self.input_shape[2] * self.input_shape[3]]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x.reshape([self.input_shape[0], self.input_shape[1] * self.input_shape[2] * self.input_shape[3]])\n",
    "        return y\n",
    "    def backward(self, y):\n",
    "        x = np.reshape(y, [self.input_shape[0], self.input_shape[1], self.input_shape[2], self.input_shape[3]])\n",
    "        return x\n",
    "\n",
    "def test_():\n",
    "    index = 1\n",
    "    img = train_data[index:index+2, ...]\n",
    "    y = train_labels[index:index+2,...]\n",
    "    print(\"img.shape: \\t\", img.shape)\n",
    "    \n",
    "    conv = Convolution(img.shape, k_size=3, k_num=2, strides=1, seed=2330)\n",
    "    conv_out = conv.forward(img)\n",
    "    print(\"conv_out.shape: \", conv_out.shape)\n",
    "\n",
    "    relu=Relu(conv.output_shape)\n",
    "    relu_out = relu.forward(conv_out)\n",
    "    print(\"relu_out.shape: \", relu_out.shape)\n",
    "    \n",
    "    pool = max_pool(relu.output_shape,2,2)\n",
    "    pool_out = pool.forward(relu_out)\n",
    "    print(\"pool_out.shape: \", pool_out.shape)\n",
    "    \n",
    "    flat = flatten(pool.output_shape)\n",
    "    flat_out = flat.forward(pool_out)\n",
    "    print(\"flat_out.shape: \", flat_out.shape)\n",
    "    \n",
    "    flat_back = flat.backward(flat_out)\n",
    "    print(\"flat_back.shape:\", flat_back.shape)\n",
    "    \n",
    "    pool_back = pool.backward(flat_back)\n",
    "    print(\"pool_back.shape:\", pool_back.shape)\n",
    "    \n",
    "    relu_back = relu.backward(pool_back)\n",
    "    print(\"relu_back.shape:\", relu_back.shape)\n",
    "    \n",
    "    conv_back = conv.backward(relu_back, lr=0.0001)\n",
    "    print(\"conv_back.shape:\", conv_back.shape)\n",
    "    \n",
    "test_()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 全连接层\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img.shape: \t (2, 28, 28, 1)\n",
      "conv_out.shape:  (2, 26, 26, 2)\n",
      "relu_out.shape:  (2, 26, 26, 2)\n",
      "pool_out.shape:  (2, 13, 13, 2)\n",
      "flat_out.shape:  (2, 338)\n",
      "fc_out.shape: \t (2, 10)\n",
      "fc_back.shape: \t (2, 338)\n",
      "flat_back.shape: (2, 13, 13, 2)\n",
      "pool_back.shape: (2, 26, 26, 2)\n",
      "relu_back.shape: (2, 26, 26, 2)\n",
      "conv_back.shape: (2, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "class full_connection:\n",
    "    def __init__(self, input_shape, output_channels, seed=2330):\n",
    "        self.input_shape = input_shape\n",
    "        self.input_batch = input_shape[0]\n",
    "        self.input_length = input_shape[1]\n",
    "        self.output_channels = output_channels\n",
    "        \n",
    "        self.seed = seed\n",
    "        np.random.seed(self.seed)\n",
    "        \n",
    "        weights_scale = math.sqrt(self.input_length/2) \n",
    "        self.weights = np.random.standard_normal((self.input_length,self.output_channels)) / weights_scale\n",
    "        self.bias = np.random.standard_normal(self.output_channels) / weights_scale\n",
    "        \n",
    "        self.output_shape = [self.input_batch, self.output_channels]\n",
    "        self.w_gradient = np.zeros(self.weights.shape)\n",
    "        self.b_gradient = np.zeros(self.bias.shape)\n",
    "    \n",
    "    #计算全连接的前向传播，反向求导 (20 points)\n",
    "    def forward(self, x):\n",
    "        ### start your code\n",
    "        # tips: wx+b形式\n",
    "        self.x = x\n",
    "        y = np.dot(self.x, self.weights) + self.bias\n",
    "        ### end your code\n",
    "        return y\n",
    "    \n",
    "    def backward(self, delta, lr=0.0001, weight_decay=0.0004):\n",
    "        ### start your code\n",
    "        # tips: weight decay使用：(1-weightdecay)*weight-lr*w_gradient, bias类似\n",
    "        delta_back = np.dot(delta, self.weights.T)\n",
    "        self.w_gradient = np.dot(self.x.T, delta)\n",
    "        self.b_gradient = np.sum(delta, axis=0)\n",
    "        \n",
    "        self.weights = (1-weight_decay)*self.weights - lr*self.w_gradient\n",
    "        # self.bias = (1-weight_decay)*self.bias - lr*self.b_gradient\n",
    "        self.bias = (1-weight_decay)*self.bias - lr*self.bias\n",
    "        \n",
    "        self.w_gradient = np.zeros_like(self.weights)\n",
    "        self.b_gradient = np.zeros_like(self.bias)\n",
    "        ### end your code\n",
    "        return delta_back\n",
    "    \n",
    "def test_():\n",
    "    index = 1\n",
    "    img = train_data[index:index+2, ...]\n",
    "    y = train_labels[index:index+2,...]\n",
    "    print(\"img.shape: \\t\", img.shape)\n",
    "    \n",
    "    conv = Convolution(img.shape, k_size=3, k_num=2, strides=1, seed=2330)\n",
    "    conv_out = conv.forward(img)\n",
    "    print(\"conv_out.shape: \", conv_out.shape)\n",
    "\n",
    "    relu=Relu(conv.output_shape)\n",
    "    relu_out = relu.forward(conv_out)\n",
    "    print(\"relu_out.shape: \", relu_out.shape)\n",
    "    \n",
    "    pool = max_pool(relu.output_shape,2,2)\n",
    "    pool_out = pool.forward(relu_out)\n",
    "    print(\"pool_out.shape: \", pool_out.shape)\n",
    "    \n",
    "    flat = flatten(pool.output_shape)\n",
    "    flat_out = flat.forward(pool_out)\n",
    "    print(\"flat_out.shape: \", flat_out.shape)\n",
    "    \n",
    "    fc = full_connection(flat.output_shape,10,seed=SEED)\n",
    "    fc_out = fc.forward(flat_out)\n",
    "    print(\"fc_out.shape: \\t\", fc_out.shape)\n",
    "    \n",
    "    fc_back = fc.backward(fc_out,lr=0.0001)\n",
    "    print(\"fc_back.shape: \\t\",fc_back.shape)\n",
    "    \n",
    "    flat_back = flat.backward(fc_back)\n",
    "    print(\"flat_back.shape:\", flat_back.shape)\n",
    "    \n",
    "    pool_back = pool.backward(flat_back)\n",
    "    print(\"pool_back.shape:\", pool_back.shape)\n",
    "    \n",
    "    relu_back = relu.backward(pool_back)\n",
    "    print(\"relu_back.shape:\", relu_back.shape)\n",
    "    \n",
    "    conv_back = conv.backward(relu_back, lr=0.0001)\n",
    "    print(\"conv_back.shape:\", conv_back.shape)\n",
    "    \n",
    "test_()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "expect output:\n",
    "\n",
    "    img.shape: \t  (2, 28, 28, 1)\n",
    "    conv_out.shape:  (2, 28, 28, 2)\n",
    "    relu_out.shape:  (2, 28, 28, 2)\n",
    "    pool_out.shape:  (2, 14, 14, 2)\n",
    "    flat_out.shape:  (2, 392)\n",
    "    fc_out.shape:    (2, 10)\n",
    "    fc_back.shape:   (2, 392)\n",
    "    flat_back.shape: (2, 14, 14, 2)\n",
    "    pool_back.shape: (2, 28, 28, 2)\n",
    "    relu_back.shape: (2, 28, 28, 2)\n",
    "    conv_back.shape: (2, 28, 28, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Softmax 层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img.shape: \t (2, 28, 28, 1)\n",
      "conv_out.shape:  (2, 24, 24, 32)\n",
      "relu_out.shape:  (2, 24, 24, 32)\n",
      "pool_out.shape:  (2, 12, 12, 32)\n",
      "flat_out.shape:  (2, 4608)\n",
      "fc_out.shape: \t (2, 10)\n",
      "pred.shape: \t (2, 10)\n",
      "loss:  \t\t 2.2156761458064804\n",
      "loss_back.shape: (2, 10)\n",
      "fc_back.shape: \t (2, 4608)\n",
      "flat_back.shape: (2, 12, 12, 32)\n",
      "pool_back.shape: (2, 24, 24, 32)\n",
      "relu_back.shape: (2, 24, 24, 32)\n",
      "conv_back.shape: (2, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "class Softmax:\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "        self.input_batch = input_shape[0]\n",
    "        self.class_num = input_shape[1]\n",
    "        \n",
    "        self.softmax = np.zeros(self.input_shape)\n",
    "        self.delta = np.zeros(self.input_shape)\n",
    "        \n",
    "    def cal_loss(self, x, label):\n",
    "        self.prediction(x)\n",
    "        loss = 0\n",
    "        for i in range(self.input_batch):\n",
    "            loss -= np.sum(np.log(self.softmax[i]) * label[i])\n",
    "        loss /= self.input_batch\n",
    "        return loss\n",
    "    \n",
    "    #计算softmax的前向传播，反向求导（10 points）\n",
    "    def prediction(self, x):\n",
    "        for i in range(self.input_batch):\n",
    "            ### start your code\n",
    "            xx = x[i]\n",
    "            e = np.exp(xx - np.max(xx))\n",
    "            self.softmax[i] = e / np.sum(e)\n",
    "            ## end your code\n",
    "        return self.softmax\n",
    "    \n",
    "    def backward(self, label):\n",
    "        for i in range(self.input_batch):\n",
    "            ### start your code\n",
    "            self.delta[i] = self.softmax[i] - label[i]\n",
    "            ## end your code\n",
    "        return self.delta\n",
    "    \n",
    "def test_():\n",
    "    index = 1\n",
    "    img = train_data[index:index+2, ...]\n",
    "    y = train_labels[index:index+2,...]\n",
    "    print(\"img.shape: \\t\", img.shape)\n",
    "    \n",
    "    conv = Convolution(img.shape, k_size=5, k_num=32, strides=1, seed=2330)\n",
    "    conv_out = conv.forward(img)\n",
    "    print(\"conv_out.shape: \", conv_out.shape)\n",
    "\n",
    "    relu=Relu(conv.output_shape)\n",
    "    relu_out = relu.forward(conv_out)\n",
    "    print(\"relu_out.shape: \", relu_out.shape)\n",
    "    \n",
    "    pool = max_pool(relu.output_shape,2,2)\n",
    "    pool_out = pool.forward(relu_out)\n",
    "    print(\"pool_out.shape: \", pool_out.shape)\n",
    "    \n",
    "    flat = flatten(pool.output_shape)\n",
    "    flat_out = flat.forward(pool_out)\n",
    "    print(\"flat_out.shape: \", flat_out.shape)\n",
    "    \n",
    "    fc = full_connection(flat.output_shape,10,seed=SEED)\n",
    "    fc_out = fc.forward(flat_out)\n",
    "    print(\"fc_out.shape: \\t\", fc_out.shape)\n",
    "    \n",
    "    softmax = Softmax(fc.output_shape)\n",
    "    \n",
    "    pred = softmax.prediction(fc_out)\n",
    "    print(\"pred.shape: \\t\", pred.shape)\n",
    "    \n",
    "    loss = softmax.cal_loss(fc_out, y)\n",
    "    print(\"loss:  \\t\\t\", loss)\n",
    "    \n",
    "    loss_back = softmax.backward(label=y)\n",
    "    print(\"loss_back.shape:\", loss_back.shape)\n",
    "    \n",
    "    fc_back = fc.backward(loss_back,lr=0.0001)\n",
    "    print(\"fc_back.shape: \\t\",fc_back.shape)\n",
    "    \n",
    "    flat_back = flat.backward(fc_back)\n",
    "    print(\"flat_back.shape:\", flat_back.shape)\n",
    "    \n",
    "    pool_back = pool.backward(flat_back)\n",
    "    print(\"pool_back.shape:\", pool_back.shape)\n",
    "    \n",
    "    relu_back = relu.backward(pool_back)\n",
    "    print(\"relu_back.shape:\", relu_back.shape)\n",
    "    \n",
    "    conv_back = conv.backward(relu_back, lr=0.0001)\n",
    "    print(\"conv_back.shape:\", conv_back.shape)\n",
    "    \n",
    "    \n",
    "test_()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "expect output:\n",
    "    \n",
    "    img.shape: \t  (2, 28, 28, 1)\n",
    "    conv_out.shape:  (2, 24, 24, 32)\n",
    "    relu_out.shape:  (2, 24, 24, 32)\n",
    "    pool_out.shape:  (2, 12, 12, 32)\n",
    "    flat_out.shape:  (2, 4608)\n",
    "    fc_out.shape:    (2, 10)\n",
    "    pred.shape: \t (2, 10)\n",
    "    loss:  \t\t   2.32...\n",
    "    loss_back.shape: (2, 10)\n",
    "    fc_back.shape:   (2, 4608)\n",
    "    flat_back.shape: (2, 12, 12, 32)\n",
    "    pool_back.shape: (2, 24, 24, 32)\n",
    "    relu_back.shape: (2, 24, 24, 32)\n",
    "    conv_back.shape: (2, 28, 28, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 搭建CNN网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self,num_labels=10, batch_size=64, image_size=28, num_channels=1, seed=66478):\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.num_channels = num_channels\n",
    "        self.seed = seed\n",
    "        self.num_labels=num_labels\n",
    "        self.net_builder()\n",
    "        \n",
    "    def net_builder(self):\n",
    "        self.conv1 = Convolution([self.batch_size, self.image_size, self.image_size, self.num_channels], k_size=5, k_num=6, strides=1, seed=2330)\n",
    "        self.relu1 = Relu(self.conv1.output_shape)\n",
    "        self.pool1 = max_pool(self.relu1.output_shape, 2,2)\n",
    "            \n",
    "        self.conv2 = Convolution(self.pool1.output_shape, k_size=5, k_num=16, strides=1, seed=2330)\n",
    "        self.relu2 = Relu(self.conv2.output_shape)\n",
    "        self.pool2 = max_pool(self.relu2.output_shape, 2,2)\n",
    "            \n",
    "        self.flat = flatten(self.pool2.output_shape)\n",
    "        self.fc1 = full_connection(self.flat.output_shape,512,seed=SEED)\n",
    "        self.relu3 = Relu(self.fc1.output_shape)\n",
    "            \n",
    "        self.fc2 = full_connection(self.relu3.output_shape,10,seed=SEED)\n",
    "            \n",
    "        self.softmax = Softmax(self.fc2.output_shape)\n",
    "        \n",
    "    def cal_forward(self, x, get_pred=False):\n",
    "        conv1_out = self.conv1.forward(x)\n",
    "        relu1_out = self.relu1.forward(conv1_out)\n",
    "        pool1_out = self.pool1.forward(relu1_out)\n",
    "        \n",
    "        conv2_out = self.conv2.forward(pool1_out)\n",
    "        relu2_out = self.relu2.forward(conv2_out)\n",
    "        pool2_out = self.pool2.forward(relu2_out)\n",
    "        \n",
    "        flat_out = self.flat.forward(pool2_out)\n",
    "        fc1_out = self.fc1.forward(flat_out)\n",
    "        relu3_out = self.relu3.forward(fc1_out)\n",
    "        \n",
    "        fc2_out = self.fc2.forward(relu3_out)\n",
    "\n",
    "        pred = self.softmax.prediction(fc2_out)\n",
    "        if get_pred:\n",
    "            return pred, fc2_out\n",
    "        return np.argmax(pred,axis=1)\n",
    "\n",
    "    def fit(self, x, y, lr):\n",
    "        ### start your code （20 points）\n",
    "        # 包括前向传播（和上面forward形式一致），到计算pred\n",
    "        # 在已知forward的结构条件下，反向逐步计算梯度，从计算loss开始\n",
    "        # tips: 都是用前面构建的函数搭建，直接调用backward即可，重点在于求导顺序\n",
    "        \n",
    "        # forward\n",
    "        pred, fc2_out = self.cal_forward(x, get_pred=True)\n",
    "        loss = self.softmax.cal_loss(fc2_out, y)\n",
    "        # backward\n",
    "        b = self.softmax.backward(label=y)\n",
    "        b = self.fc2.backward(b, lr=lr)\n",
    "        b = self.relu3.backward(b)\n",
    "        b = self.fc1.backward(b, lr=lr)\n",
    "        b = self.flat.backward(b)\n",
    "        b = self.pool2.backward(b)\n",
    "        b = self.relu2.backward(b)\n",
    "        b = self.conv2.backward(b, lr=lr)\n",
    "        b = self.pool1.backward(b)\n",
    "        b = self.relu1.backward(b)\n",
    "        b = self.conv1.backward(b, lr=lr)\n",
    "        \n",
    "        #end your code\n",
    "        return loss, np.argmax(pred, axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy\n",
    "def cal_acc(predictions, labels):\n",
    "    return (100.0 * np.sum(predictions == labels) /predictions.shape[0]) \n",
    "\n",
    "def eval_in_batches(data,cnn):\n",
    "    size = data.shape[0]\n",
    "    if size < EVAL_BATCH_SIZE:\n",
    "        raise ValueError(\"batch size for evals larger than dataset: %d\" % size)\n",
    "    predictions = np.zeros(size)\n",
    "    for begin in xrange(0, size, EVAL_BATCH_SIZE):\n",
    "        end = begin + EVAL_BATCH_SIZE\n",
    "        if end <= size:\n",
    "            x = data[begin:end, ...]\n",
    "            predictions[begin:end] = cnn.cal_forward(x)\n",
    "        else:\n",
    "            x = data[-EVAL_BATCH_SIZE:, ...]\n",
    "            batch_predictions = cnn.cal_forward(x)\n",
    "            predictions[begin:] = batch_predictions[begin - size:]\n",
    "    return predictions\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 (epoch 0.00)\n",
      "Minibatch loss: 2.387\n",
      "Minibatch acc:  9.4%\n",
      "Validation error: 8.7%\n",
      "Step 100 (epoch 0.12)\n",
      "Minibatch loss: 0.287\n",
      "Minibatch acc:  92.2%\n",
      "Validation error: 90.4%\n",
      "Step 200 (epoch 0.23)\n",
      "Minibatch loss: 0.223\n",
      "Minibatch acc:  90.6%\n",
      "Validation error: 94.9%\n",
      "Step 300 (epoch 0.35)\n",
      "Minibatch loss: 0.130\n",
      "Minibatch acc:  95.3%\n",
      "Validation error: 94.8%\n",
      "Step 400 (epoch 0.47)\n",
      "Minibatch loss: 0.239\n",
      "Minibatch acc:  90.6%\n",
      "Validation error: 96.3%\n",
      "Step 500 (epoch 0.58)\n",
      "Minibatch loss: 0.250\n",
      "Minibatch acc:  95.3%\n",
      "Validation error: 95.8%\n",
      "Step 600 (epoch 0.70)\n",
      "Minibatch loss: 0.144\n",
      "Minibatch acc:  98.4%\n",
      "Validation error: 95.7%\n",
      "Step 700 (epoch 0.81)\n",
      "Minibatch loss: 0.049\n",
      "Minibatch acc:  98.4%\n",
      "Validation error: 97.7%\n",
      "Step 800 (epoch 0.93)\n",
      "Minibatch loss: 0.070\n",
      "Minibatch acc:  95.3%\n",
      "Validation error: 97.3%\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN(num_labels=10, batch_size=64, image_size=28, num_channels=1, seed=SEED)\n",
    "learning_rate = 0.01\n",
    "\n",
    "for step in xrange(int(MAX_EPOCHS * train_size) // BATCH_SIZE):\n",
    "    offset = (step * BATCH_SIZE) % (train_size - BATCH_SIZE)\n",
    "    batch_x = train_data[offset:(offset + BATCH_SIZE), ...]\n",
    "    batch_y = train_labels[offset:(offset + BATCH_SIZE)]\n",
    "\n",
    "    loss, predictions = cnn.fit(batch_x,batch_y,learning_rate)\n",
    "    \n",
    "    if step % EVAL_FREQUENCY == 0:\n",
    "        acc = cal_acc(predictions, np.argmax(batch_y, axis=1))\n",
    "        print('Step %d (epoch %.2f)' % (step, float(step) * BATCH_SIZE / train_size))\n",
    "        print('Minibatch loss: %.3f' % loss)\n",
    "        print('Minibatch acc:  %.1f%%' % acc)\n",
    "        val_predictions = eval_in_batches(validation_data[0:1000, ...],cnn)\n",
    "        val_acc = cal_acc(val_predictions, np.argmax(validation_labels[0:1000], axis=1))\n",
    "        print('Validation error: %.1f%%' % val_acc)\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试过程，输出测试集准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data acc: 95.1%\n"
     ]
    }
   ],
   "source": [
    "test_predictions = eval_in_batches(test_data, cnn)\n",
    "test_acc = cal_acc(test_predictions, test_labels)\n",
    "print(\"test data acc: %.1f%%\" % test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
